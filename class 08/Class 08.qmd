---
title: "Class 08"
author: "Aaron Liu A13908620"
format: pdf
---

##Open data
```{r}
fna.data <- "WisconsinCancer.csv"
wisc.df <- read.csv(fna.data, row.names=1)
head(wisc.df)
```
##Removing the diagnosis
```{r}
wisc.data <- wisc.df[,-1]
```

##Creating a diagnosis vector 
```{r}
diagnosis <- wisc.df$diagnosis
```

>Q1. How many observations are in this dataset?

```{r}
nrow(wisc.data)
```

>Q2. How many of the observations have a malignant diagnosis?

```{r}
logical<- diagnosis=="M"
nrow(wisc.df[logical,])
```

> Q3. How many variables/features in the data are suffixed with _mean?

```{r}
?grep()
length(grep("_mean", colnames(wisc.df)))
```

##PCA!

##checking SD

```{r}
colMeans(wisc.data)
apply(wisc.data,2,sd)
```

```{r}
wisc.pr <- prcomp(wisc.data,scale. = T)
a <- summary(wisc.pr)
a
```
>Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

44.27%

>Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

PC1, PC2, PC3 is enough
```{r}
b <- a$importance
c<-b[3,]
which(c>=0.7)[1]
sum (b[2, 1:3])>0.7

#or using cumulative proportion
```



>Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

```{r}
sum (b[2, 1:7])>0.9
#or using cumulative proportion
```
7 PCs

>Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

```{r}
?biplot
biplot(wisc.pr)

```
It is so messy!!!!!Not going to interpret this. 

```{r}
# Scatter plot observations by components 1 and 2
diagnosis1<-factor(diagnosis)
plot(wisc.pr$x[,1:2] , col = diagnosis1 , 
     xlab = "PC1", ylab = "PC2")
```
>Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

```{r}
plot(wisc.pr$x[, c(1,3) ], col = diagnosis1, 
     xlab = "PC1", ylab = "PC3")
```
Very similar results with PC2 better, indicating PC1 already separated out most of the difference. 

##GGPLOT!

```{r}
library(ggplot2)
# Create a data.frame for ggplot
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis

# Load the ggplot2 package
library(ggplot2)

# Make a scatter plot colored by diagnosis
ggplot(df) + 
  aes(PC1, PC2, col=diagnosis) + 
  geom_point()
```

##Variance
```{r}
pr.var <- wisc.pr$sdev^2
pr.var

```
```{r}
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)
# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```
```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```
```{r}
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```

>Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean? This tells us how much this original feature contributes to the first PC.


```{r}
d<-wisc.pr$rotation
d["concave.points_mean",1]

```

##Hierarchical clustering


```{r}
data.scaled <- scale(wisc.data)
```

```{r}
data.dist <- dist(data.scaled)
?hclust
wisc.hclust <- hclust(data.dist, method="complete" )
```
##Plotting 

```{r}
plot(wisc.hclust)
?abline
abline(h=19, col="red", lty=2)
```

```{r}
?cutree
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
table(wisc.hclust.clusters, diagnosis)
```
##explore clustering 

>Q11. OPTIONAL: Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10? How do you judge the quality of your result in each case?

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k=6)
table(wisc.hclust.clusters, diagnosis)


for (n in 2:10){
  wisc.hclust.clusters <- cutree(wisc.hclust, k=n)
  fake<-table(wisc.hclust.clusters, diagnosis)
}
  
#too much work
```

##different clustering method

```{r}
#single
wisc.hclust_single <- hclust(data.dist, method="single" )
plot(wisc.hclust_single)

```
```{r}
#average
wisc.hclust_average <- hclust(data.dist, method="average" )
plot(wisc.hclust_average)
```
>Q12. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

Complete, since it allows greater separation of the clusters. 

## PCA clustering 
```{r}
wisc.pr.dist<-dist(wisc.pr$x[,1:7])
wisc.pr.hclust<-hclust(wisc.pr.dist, method="ward.D2")
plot(wisc.pr.hclust)
```

```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps, diagnosis)
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
```

```{r}
plot(wisc.pr$x[,1:2], col=as.factor(diagnosis))

```
Some difference 
```{r}
g <- as.factor(grps)
g <- relevel(g,2)
plot(wisc.pr$x[,1:2], col=g)
```
```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x), method="ward.D2")
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
```

>Q13. How well does the newly created model with four clusters separate out the two diagnoses?

```{r}
#PC7 clustering
table(wisc.pr.hclust.clusters, diagnosis)
table_1<-table(wisc.pr.hclust.clusters, diagnosis)
false_positive<-table_1[1,1]/sum(table_1[1,1], table_1[1,2])
false_negative<-table_1[2,2]/sum(table_1[2,1], table_1[2,2])
print(paste(false_positive, false_negative))
```
>Q14. How well do the hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

```{r}
#Normal hierarchial clustering
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
table(wisc.hclust.clusters, diagnosis)
```
worse, lot more false negative and positive in PC clustering. 

##Sensitivity/Specificity
>Q15. OPTIONAL: Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

```{r}
#PC7 clustering
table_1<-table(wisc.pr.hclust.clusters, diagnosis)
table_1

#Sensitivity: 

print(paste("Sensitivity", 164/(164+48)))

#Specificity:

print(paste("Specificity", 337/(337+20)))
```

##Prediction
```{r}
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```
```{r}
plot(wisc.pr$x[,1:2], col=g)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

>Q16. Which of these new patients should we prioritize for follow up based on your results?

Patient 2!!

sessionInfo()

